{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing the convNet model on real input data\n",
    "\n",
    "We will test the model on the [Malaria Infected Cells](https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria) dataset. The goal is to predict which cells are infected by malaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fea00d29670>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.convNet.model import convNet\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s:%(message)s\", level=logging.INFO)\n",
    "\n",
    "# Ensure reproducibility\n",
    "torch.manual_seed(767365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll scale down these images quite a bit so they can run comfortably on CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "H = W = 32\n",
    "# Define transformations\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([H,W]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=(-15,15),\n",
    "            translate=(0,.2),\n",
    "            scale=(.8, 1.2),\n",
    "            shear=0.1,\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize([H,W]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the imageFolder datasets. Note that these take different transforms. We don't want to apply shears & random flips to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_folder = \"/Users/jasperginn/PycharmProjects/Pneumonia/data/cell_images/train\"\n",
    "val_data_folder = \"/Users/jasperginn/PycharmProjects/Pneumonia/data/cell_images/val\"\n",
    "# Set up data loaders\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root = train_data_folder,\n",
    "    transform = transform[\"train\"],\n",
    ")\n",
    "# Get classes\n",
    "#print(train_dataset.class_to_idx)\n",
    "#train_dataset.class_to_idx = {\"Uninfected\": 0, \"Parasitized\": 1}\n",
    "\n",
    "# Validation data\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root = val_data_folder,\n",
    "    transform = transform[\"test\"]\n",
    ")\n",
    "#val_dataset.class_to_idx = {\"Uninfected\": 0, \"Parasitized\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up the model. Given that the last layer of the model does not perform a transformation, we have to use BCEWithLogitsLoss(). This combines the sigmoid function and loss function into one layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             608\n",
      "         MaxPool2d-2            [-1, 8, 16, 16]               0\n",
      "convolutional_block-3            [-1, 8, 16, 16]               0\n",
      "            Conv2d-4           [-1, 16, 12, 12]           3,216\n",
      "         MaxPool2d-5             [-1, 16, 6, 6]               0\n",
      "convolutional_block-6             [-1, 16, 6, 6]               0\n",
      "            Conv2d-7             [-1, 32, 4, 4]           4,640\n",
      "         MaxPool2d-8             [-1, 32, 2, 2]               0\n",
      "convolutional_block-9             [-1, 32, 2, 2]               0\n",
      "          Flatten-10                  [-1, 128]               0\n",
      "          Dropout-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 32]           4,128\n",
      "           Linear-13                    [-1, 8]             264\n",
      "           Linear-14                    [-1, 1]               9\n",
      "================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.13\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = convNet(dropout=0.2)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "summary(net, (3, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.690\n",
      "[1,   200] loss: 0.654\n",
      "[1,   300] loss: 0.621\n",
      "[1,   400] loss: 0.584\n",
      "Accuracy on train set is: 0.6309652390651801\n",
      "Accuracy on validation set is: 0.8170797413793103\n",
      "[2,   100] loss: 0.510\n",
      "[2,   200] loss: 0.463\n",
      "[2,   300] loss: 0.423\n",
      "[2,   400] loss: 0.400\n",
      "Accuracy on train set is: 0.8694977487135507\n",
      "Accuracy on validation set is: 0.915948275862069\n",
      "[3,   100] loss: 0.366\n",
      "[3,   200] loss: 0.348\n",
      "[3,   300] loss: 0.325\n",
      "[3,   400] loss: 0.311\n",
      "Accuracy on train set is: 0.9188230328044598\n",
      "Accuracy on validation set is: 0.9362877155172413\n",
      "[4,   100] loss: 0.299\n",
      "[4,   200] loss: 0.294\n",
      "[4,   300] loss: 0.276\n",
      "[4,   400] loss: 0.260\n",
      "Accuracy on train set is: 0.9322918900085763\n",
      "Accuracy on validation set is: 0.9280711206896551\n",
      "[5,   100] loss: 0.257\n",
      "[5,   200] loss: 0.255\n",
      "[5,   300] loss: 0.247\n",
      "[5,   400] loss: 0.237\n",
      "Accuracy on train set is: 0.9369720197255574\n",
      "Accuracy on validation set is: 0.9562230603448276\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    acc = 0\n",
    "    batches = 0\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        batch_x, batch_y = data\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass, backward pass\n",
    "        outputs = net(batch_x)\n",
    "        loss = criterion(outputs.view(-1), batch_y.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        # Optimize parameters\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        batches += 1\n",
    "        outputs_class = outputs > 0\n",
    "        acc_current = torch.sum(outputs_class.view(-1) == batch_y).numpy() / batch_y.shape[0]\n",
    "        acc += acc_current\n",
    "    acc /= batches\n",
    "    print(\"Accuracy on train set is: %s\" % acc)\n",
    "    # On cross-validation set\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        batches = 0\n",
    "        for i, data in enumerate(val_data_loader, 0):\n",
    "            batch_x, batch_y = data\n",
    "            outputs = net(batch_x)\n",
    "            loss = criterion(outputs.view(-1), batch_y.type(torch.FloatTensor)).item()\n",
    "            # Predict\n",
    "            outputs_class = outputs > 0\n",
    "            acc_current = torch.sum(outputs_class.view(-1) == batch_y).numpy() / batch_y.shape[0]\n",
    "            batches += 1\n",
    "            acc += acc_current\n",
    "        acc /= batches\n",
    "        print(\"Accuracy on validation set is: %s\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this final model to predict the accuracy on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set is: 0.984375\n"
     ]
    }
   ],
   "source": [
    "test_data_folder = \"/Users/jasperginn/PycharmProjects/Pneumonia/data/cell_images/test\"\n",
    "# Define the dataset\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root = test_data_folder,\n",
    "    transform = transform[\"test\"]\n",
    ")\n",
    "# Set up the data loader\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    acc = 0\n",
    "    batches = 0\n",
    "    for i, data in enumerate(test_data_loader, 0):\n",
    "        batch_x, batch_y = data\n",
    "        outputs = net(batch_x)\n",
    "        loss = criterion(outputs.view(-1), batch_y.type(torch.FloatTensor)).item()\n",
    "        # Predict\n",
    "        outputs_class = outputs > 0\n",
    "        acc_current = torch.sum(outputs_class.view(-1) == batch_y).numpy() / batch_y.shape[0]\n",
    "        batches += 1\n",
    "        acc += acc_current\n",
    "    acc /= batches\n",
    "    print(\"Accuracy on validation set is: %s\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "So this model works very well on this dataset. By performing hyperparameter optimization we could probably squeeze out a little more performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"../models/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
